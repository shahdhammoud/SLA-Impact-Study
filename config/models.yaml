# Generative model configurations

models:
  ctgan:
    name: "CTGAN"
    framework: "sdv"
    default_params:
      epochs: 300
      batch_size: 500
      generator_dim: [256, 256]
      discriminator_dim: [256, 256]
      generator_lr: 0.0002
      discriminator_lr: 0.0002
      discriminator_steps: 1
      pac: 10
    tuning_params:
      epochs: [100, 300, 500]
      batch_size: [250, 500, 1000]
      generator_lr: [0.0001, 0.0005]
      discriminator_lr: [0.0001, 0.0005]
      pac: [5, 10, 20]

  tabddpm:
    name: "TabDDPM"
    framework: "custom"  # Will use tab-ddpm codebase
    default_params:
      num_timesteps: 1000
      gaussian_loss_type: "mse"
      scheduler: "cosine"
      model_type: "mlp"
      num_layers: 4
      hidden_dim: 256
      dropout: 0.0
      lr: 0.002
      weight_decay: 0.0001
      batch_size: 1024
      epochs: 1000
    tuning_params:
      num_timesteps: [500, 1000, 2000]
      hidden_dim: [128, 256, 512]
      lr: [0.001, 0.002, 0.004]
      batch_size: [512, 1024, 2048]

  gmm:
    name: "Gaussian Mixture Model"
    framework: "sklearn"
    default_params:
      n_components: 10
      covariance_type: "full"
      max_iter: 100
      n_init: 10
      random_state: 42
    tuning_params:
      n_components: [5, 10, 20, 30]
      covariance_type: ["full", "tied", "diag", "spherical"]
      max_iter: [100, 200]

  bayesian_network:
    name: "Bayesian Network"
    framework: "pgmpy"
    default_params:
      learning_algorithm: "hillclimb"  # Structure learning for generative BN
      scoring_method: "bic"
      max_iter: 1000
      random_state: 42
    tuning_params:
      learning_algorithm: ["hillclimb", "pc"]
      scoring_method: ["bic", "k2"]

# General training settings
training:
  use_gpu: true
  gpu_id: 0
  early_stopping: true
  patience: 50
  save_checkpoints: true
  checkpoint_dir: "outputs/models"
